{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#What packages were installed:\n",
    "# \n",
    "# python 3.9.7\n",
    "# pip 21.2.4\n",
    "# tensorflow 2.8.0\n",
    "# opencv\n",
    "# https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html\n",
    "# (CPU):\n",
    "#     - download protobuf version: https://github.com/protocolbuffers/protobuf/releases/tag/v3.19.4\n",
    "#     - Add to environment path <PROTOBUF_PATH>/bin\n",
    "#     - run:\n",
    "#         # From within TensorFlow/models/research/\n",
    "#         protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "#         cp object_detection/packages/tf2/setup.py .                 //may need to run this file seperately\n",
    "#         python -m pip install --use-feature=2020-resolver .\n",
    "\n",
    "#         python object_detection/builders/model_builder_tf2_test.py\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = 'workspace'\n",
    "ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n",
    "IMAGE_PATH = WORKSPACE_PATH+'/cropped_images'\n",
    "MODEL_PATH = WORKSPACE_PATH+'/models'\n",
    "CHECKPOINT_PATH = MODEL_PATH+'/my_ssd_mob' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'my_ssd_mob'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME+'/pipeline.config'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.builders import model_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(CHECKPOINT_PATH, 'ckpt-6')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def crop_breasts(images):\n",
    "    category_index = label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH + '/label_map.pbtxt')\n",
    "\n",
    "    images_out = []\n",
    "\n",
    "    for i in range(images.shape[0]):\n",
    "        in_tensor = tf.convert_to_tensor(np.expand_dims(images[i],0), dtype=tf.float32)\n",
    "        detections = detect_fn(in_tensor)\n",
    "\n",
    "        num_detections = int(detections.pop('num_detections'))\n",
    "\n",
    "        detections = {key: value[0, :num_detections].numpy()\n",
    "                    for key, value in detections.items()}\n",
    "\n",
    "        if detections['detection_scores'][0] < 0.75:\n",
    "            print('Score < 0.75 for i=' + str(i))\n",
    "        box = detections['detection_boxes'][0]\n",
    "\n",
    "        image_np_crop = images[i].copy()\n",
    "        left = math.floor(box[0] * images.shape[1])\n",
    "        right = math.ceil(box[2] * images.shape[1])\n",
    "        bot = math.floor(box[1] * images.shape[1])\n",
    "        top = math.ceil(box[3] * images.shape[1])\n",
    "        cropped_img = image_np_crop[left:right, bot:top]\n",
    "        name = './Image_' + str(i) + '_crop.jpeg'       #\n",
    "        cv2.imwrite(IMAGE_PATH +'/{}'.format(name) , cropped_img)\n",
    "\n",
    "    \n",
    "    return np.asarray(images_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "img = cv2.imread(\"test_images_kaggle/images/2016_BC003122_ CC_L.jpg\")  #test_images_kaggle/images\n",
    "crop_breasts(np.asarray([img]))  #np.asarray([img,img])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76ac48093e489c919447ca0a52401241b821bdb534a7742f40bfa14292fd3c3a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
